{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from functools import reduce \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logistic_regression` function performs logistic regression on a given dataset. The function takes two arguments:  data , which is the dataset, and  result_group , which specifies the target variable to be predicted (1 for \"MCQ160L\" or 2 for \"MCQ220\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(data, result_group):\n",
    "\n",
    "    if result_group == 1 :\n",
    "        # Split the data into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data.drop([\"MCQ220\", \"MCQ160L\"], axis=1), data[\"MCQ160L\"], test_size=0.2)\n",
    "\n",
    "    elif result_group == 2:\n",
    "        # Split the data into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data.drop([\"MCQ220\", \"MCQ160L\"], axis=1), data[\"MCQ220\"], test_size=0.2)\n",
    "\n",
    "\n",
    "    # Train the logistic regression model on the training data\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the logistic regression model on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"\\n Accuracy:\", accuracy)\n",
    "    \n",
    "    # Generate the confusion matrix\n",
    "    confusion_matrix_logisticR= confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n Confusion Matrix:\")\n",
    "    print(confusion_matrix_logisticR)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of First Aproach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      " The logistic regression for Liver disease in first approch base on PCA dimension reduction method is:\n",
      "\n",
      " Accuracy: 0.8820638820638821\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 728    0  110    0]\n",
      " [   3    0   51    0]\n",
      " [  74    0 1067    0]\n",
      " [   0    0    2    0]]\n",
      "**************************************************\n",
      " The logistic regression for Cancer in first approch base on PCA dimension reduction method is:\n",
      "\n",
      " Accuracy: 0.8324324324324325\n",
      "\n",
      " Confusion Matrix:\n",
      "[[803   0 125]\n",
      " [  8   0  97]\n",
      " [111   0 891]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      " The logistic regression for Liver disease in first approch base on Isomap dimension reduction method is:\n",
      "\n",
      " Accuracy: 0.8162162162162162\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 608    0  253    0]\n",
      " [   4    0   42    0]\n",
      " [  72    0 1053    0]\n",
      " [   0    0    3    0]]\n",
      "**************************************************\n",
      " The logistic regression for Cancer in first approch base on Isomap dimension reduction method is:\n",
      "\n",
      " Accuracy: 0.7754299754299754\n",
      "\n",
      " Confusion Matrix:\n",
      "[[650   0 273]\n",
      " [  8   0  98]\n",
      " [ 78   0 928]]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "path = \"/home/asma-rashidian/Documents/DrRahmani_projects/project1/data/result/integrated_data_p2.csv\"\n",
    "data = pd.read_csv(path)\n",
    "## PCA \n",
    "print(\"-\" * 100)\n",
    "print(\" The logistic regression for Liver disease in first approch base on PCA dimension reduction method is:\")\n",
    "logistic_regression(data, 1)\n",
    "print(\"*\" * 50)\n",
    "print(\" The logistic regression for Cancer in first approch base on PCA dimension reduction method is:\")\n",
    "logistic_regression(data, 2)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "## Isomap\n",
    "path = \"/home/asma-rashidian/Documents/DrRahmani_projects/project1/data/result/integrated_isomap.csv\"\n",
    "data = pd.read_csv(path)\n",
    "print(\"-\" * 100)\n",
    "print(\" The logistic regression for Liver disease in first approch base on Isomap dimension reduction method is:\")\n",
    "logistic_regression(data, 1)\n",
    "print(\"*\" * 50)\n",
    "print(\" The logistic regression for Cancer in first approch base on Isomap dimension reduction method is:\")\n",
    "logistic_regression(data, 2)\n",
    "print(\"-\" * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      " The logistic regression for Liver disease in first approch base on PCA dimension reduction method is:\n",
      "\n",
      " Accuracy: 0.88992628992629\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 775    0   71    0]\n",
      " [   3    0   36    0]\n",
      " [ 113    0 1036    0]\n",
      " [   0    0    1    0]]\n",
      "**************************************************\n",
      " The logistic regression for Cancer in first approch base on PCA dimension reduction method is:\n",
      "\n",
      " Accuracy: 0.8501228501228502\n",
      "\n",
      " Confusion Matrix:\n",
      "[[807   0  76]\n",
      " [  3   0 103]\n",
      " [121   2 923]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      " The logistic regression for Liver disease in first approch base on Isomap dimension reduction method is:\n",
      "\n",
      " Accuracy: 0.7906633906633906\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 605    0  307    0]\n",
      " [   0    0   45    0]\n",
      " [  73    0 1004    0]\n",
      " [   0    0    1    0]]\n",
      "**************************************************\n",
      " The logistic regression for Cancer in first approch base on Isomap dimension reduction method is:\n",
      "\n",
      " Accuracy: 0.7882063882063882\n",
      "\n",
      " Confusion Matrix:\n",
      "[[620   0 255]\n",
      " [  6   0  98]\n",
      " [ 72   0 984]]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "path = \"/home/asma-rashidian/Documents/DrRahmani_projects/project1/data/result/pca_transformation_outlier_removal.csv\"\n",
    "data = pd.read_csv(path)\n",
    "## PCA \n",
    "print(\"-\" * 100)\n",
    "print(\" The logistic regression for Liver disease in first approch base on PCA dimension reduction method is:\")\n",
    "logistic_regression(data, 1)\n",
    "print(\"*\" * 50)\n",
    "print(\" The logistic regression for Cancer in first approch base on PCA dimension reduction method is:\")\n",
    "logistic_regression(data, 2)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "## Isomap\n",
    "path = \"/home/asma-rashidian/Documents/DrRahmani_projects/project1/data/result/isomap_transformation_outlier_removal.csv\"\n",
    "data = pd.read_csv(path)\n",
    "print(\"-\" * 100)\n",
    "print(\" The logistic regression for Liver disease in first approch base on Isomap dimension reduction method is:\")\n",
    "logistic_regression(data, 1)\n",
    "print(\"*\" * 50)\n",
    "print(\" The logistic regression for Cancer in first approch base on Isomap dimension reduction method is:\")\n",
    "logistic_regression(data, 2)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First approach\n",
    "\n",
    "For the liver disease classification task using PCA dimension reduction method:\n",
    "- The accuracy of the logistic regression model is approximately 0.890, indicating that the model predicted the correct outcome for around 89.0% of the test samples.\n",
    "- The confusion matrix shows the distribution of predicted classes compared to the actual classes. It reveals that the model made correct predictions for 775 samples of class 1, 0 samples of class 2, 1036 samples of class 3, and 0 samples of class 4.\n",
    "\n",
    "For the cancer classification task using PCA dimension reduction method:\n",
    "- The accuracy of the logistic regression model is approximately 0.850, indicating that the model predicted the correct outcome for around 85.0% of the test samples.\n",
    "- The confusion matrix shows the distribution of predicted classes compared to the actual classes. It reveals that the model made correct predictions for 807 samples of class 1, 0 samples of class 2, and 923 samples of class 3.\n",
    "\n",
    "For the liver disease classification task using Isomap dimension reduction method:\n",
    "- The accuracy of the logistic regression model is approximately 0.791, indicating that the model predicted the correct outcome for around 79.1% of the test samples.\n",
    "- The confusion matrix shows the distribution of predicted classes compared to the actual classes. It reveals that the model made correct predictions for 605 samples of class 1, 0 samples of class 2, 1004 samples of class 3, and 0 samples of class 4.\n",
    "\n",
    "For the cancer classification task using Isomap dimension reduction method:\n",
    "- The accuracy of the logistic regression model is approximately 0.788, indicating that the model predicted the correct outcome for around 78.8% of the test samples.\n",
    "- The confusion matrix shows the distribution of predicted classes compared to the actual classes. It reveals that the model made correct predictions for 620 samples of class 1, 0 samples of class 2, and 984 samples of class 3.\n",
    "\n",
    "These results suggest that the logistic regression models performed reasonably well in predicting the outcomes for both the liver disease and cancer classification tasks. However, further analysis and evaluation may be required to assess the overall performance and generalizability of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second aproach \n",
    "\n",
    "For the liver disease classification task:\n",
    "- The logistic regression model with PCA dimension reduction achieved an accuracy of approximately 0.890.\n",
    "- The confusion matrix shows that the model correctly predicted 775 samples of class 1, 0 samples of class 2, 1036 samples of class 3, and 0 samples of class 4.\n",
    "- The model achieved a relatively high accuracy and showed good performance in predicting class 1 and class 3.\n",
    "\n",
    "For the cancer classification task:\n",
    "- The logistic regression model with PCA dimension reduction achieved an accuracy of approximately 0.850.\n",
    "- The confusion matrix shows that the model correctly predicted 807 samples of class 1, 0 samples of class 2, and 923 samples of class 3.\n",
    "- The model achieved a relatively high accuracy and showed good performance in predicting class 1 and class 3.\n",
    "\n",
    "For the liver disease classification task with Isomap dimension reduction:\n",
    "- The logistic regression model achieved an accuracy of approximately 0.791.\n",
    "- The confusion matrix shows that the model correctly predicted 605 samples of class 1, 0 samples of class 2, 1004 samples of class 3, and 0 samples of class 4.\n",
    "- The model achieved a moderate accuracy and showed good performance in predicting class 1 and class 3.\n",
    "\n",
    "For the cancer classification task with Isomap dimension reduction:\n",
    "- The logistic regression model achieved an accuracy of approximately 0.788.\n",
    "- The confusion matrix shows that the model correctly predicted 620 samples of class 1, 0 samples of class 2, and 984 samples of class 3.\n",
    "- The model achieved a moderate accuracy and showed good performance in predicting class 1 and class 3.\n",
    "\n",
    "Overall, the logistic regression models with PCA dimension reduction performed slightly better in terms of accuracy compared to the models with Isomap dimension reduction for both the liver disease and cancer classification tasks. However, further analysis and evaluation may be required to assess the models' performance comprehensively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and Dimendion reduction Benfits VS Negative effects!\n",
    "\n",
    "In this project, attribute selection and dimensionality reduction can have several benefits: \n",
    " \n",
    "1. Improved Model Performance: By selecting relevant attributes and reducing the dimensionality of the data, we can focus on the most important features that contribute to the target variable. This can lead to improved model performance, as the model can better capture the underlying patterns and relationships in the data. \n",
    " \n",
    "2. Reduced Overfitting: Dimensionality reduction techniques help in reducing the complexity of the model by eliminating irrelevant or redundant features. This can prevent overfitting, where the model becomes too specific to the training data and fails to generalize well to unseen data. \n",
    " \n",
    "3. Faster Training and Inference: With fewer attributes and reduced dimensions, the model requires less computational resources and time for training and making predictions. This can be especially beneficial when dealing with large datasets or real-time applications. \n",
    " \n",
    "However, there can be potential negative effects of attribute selection and dimensionality reduction: \n",
    " \n",
    "1. Loss of Information: Removing certain attributes or reducing dimensions can result in the loss of some information from the original dataset. This can lead to a loss of important patterns or relationships that could be useful for the model. \n",
    " \n",
    "2. Increased Complexity: Some dimensionality reduction techniques, such as non-linear methods, can introduce additional complexity to the model. This may make it harder to interpret the results and understand the underlying relationships in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between first and second approach \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base on the results the first approach \"Considering the outliers\" had a little better performance Although they both had good results! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
